python train.py -m model.optimizer.lr=5e-5 \
                   datamodule.batch_size=8 \
                   datamodule.c_fold=0,1,2,3,4 \
                   trainer.max_epochs=20 \
                   model=instructions_ner \
                   +datamodule.sentence_mode="en" \
                   datamodule=instructions_ner \
                   architecture="google/t5-v1_1-base","google/t5-v1_1-small" \
                   datamodule.datasets=["webanno797399823581181383export-without-deft2021-and-label-studio-export.zip"] \
                   trainer=gpu \
                   logger=wandb \
		               logger.wandb.project="instructions-ner-T5v1.1"

python train.py -m model.optimizer.lr=5e-5 \
                   datamodule.batch_size=16 \
                   datamodule.c_fold=0,1,2,3,4 \
                   datamodule.datasets=["webanno797399823581181383export-without-deft2021-and-label-studio-export.zip"] \
                   trainer=gpu \
                   trainer.max_epochs=30 \
                   logger=wandb \
                   architecture="xlm-roberta-base" \
		               logger.wandb.project="xlm-bert-ner"
