batch_size: 16
sampling_params:
  _target_: vllm.SamplingParams
  max_tokens: 512
  temperature: 0.7
  top_p: 1.0
llm:
  _target_: vllm.LLM
  _partial_: true
  model: "models/merged/"
  speculative_model: "[ngram]"
  num_speculative_tokens: 5
  ngram_prompt_lookup_max: 4
  use_v2_block_manager: true
