lora:
  _target_: peft.LoraConfig
  task_type: CAUSAL_LM
  r: 8
  lora_alpha: 16
  lora_dropout: 0.05
  bias: none
  target_modules: ["q_proj", "v_proj", "k_proj", "out_proj", "fc_in", "fc_out", "wte"]

bnb_config:
  _target_: transformers.BitsAndBytesConfig
  load_in_4bit: true
  bnb_4bit_quant_type: nf4
  bnb_4bit_use_double_quant: True
  bnb_4bit_compute_dtype: bfloat16

model: mistralai/Mistral-7B-Instruct-v0.1
dataset: bio-datasets/mimic_style_transfer
sft_ratio: 0.1
gen_ratio: 0.7
seed: 0
max_seq_length: 1024
num_generated_sequences: 4
