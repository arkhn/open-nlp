resources:
  cloud: lambda
  accelerators: H100

file_mounts:
  /lora: # The directory path on the remote VM where the bucket will be mounted
    source: s3://synth-kg-lora
    mode: MOUNT # Options: MOUNT (default) or COPY

workdir: .

setup: |
  git clone -b v0.0.9 https://github.com/OptimalScale/LMFlow.git
  cd LMFlow
  conda create -n lmflow python=3.9 -y
  conda activate lmflow
  conda install -y mpi4py
  pip install -e .
  pip install vllm

run: |
  conda activate lmflow
  cd LMFlow

  # Initialize with base model
  BASE_MODEL=meta-llama/llama-2-7b-hf

  # Loop through all adapters
  print $ADAPTERS_PATHS
  IFS=',' read -ra ADAPTER_ARRAY <<< "$ADAPTERS_PATHS"
  for adapter in "${ADAPTER_ARRAY[@]}"; do
    echo "Merging adapter: $adapter ..."
    bash ./scripts/run_merge_lora.sh \
      --model_name_or_path $BASE_MODEL \
      --lora_model_path $adapter \
      --output_model_path ./merged-models
    # Update base model for next iteration
    BASE_MODEL=./merged-models
  done

  MODEL=./LMFlow/merged-models
  cd .. && python training_steps/generation/run.py --model $MODEL --output_path $OUTPUT_PATH --dataset $DATASET
